---
description: 实践是检验真理的唯一标准
---

# 第8章 容器应用故障排错实践

容器的故障始于测试的力度不够，加上开源软件的生命周期特点，在早期Docker的多个版本中，我们发现Docker并不能完全兼容各个核心Kernel的特性，加上和网络、存储的紧密结合，我们经常会碰到一些看似无法解决的问题。我们在排查过程中发现，很多问题都是牵涉到多个维护的职责范围。所以，本章的目的就是结合前人的排错经验，给大家总结出一些排障经验之谈，让大家能从中获益。

### 8.1 Docker容器线上故障排错法则

从Docker容器落地到企业内部环境之后，就已经让运维人员感受到了排错困难的窘境。在尝试重启、调试、试错的过程中，笔者收集整理了一些同行经验并结合实际情况总结出了一些可行的方法论，以此可以更加快速可靠的修复故障，维护容器生产环境。

#### 8.1.1 第一规则：使用系统级工具检查现场环境

容器系统级故障经常发生在不可预知的情况之下，当发生后运维工程师一般会经历重启、查日志、调参试错等过程。但是当遇到一些极端的系统进程卡住的情况，如 **docker ps** 卡住的情况，就会束手无策。这种进程级别的卡住情况，我们需要熟练掌握一个系统工具： **strace**。

通过执行以下命令可以获得docker ps的Linux进程调用的详细情况：

```text
$ sudo strace docker ps

```

可以过滤系统函数，只跟进指定的函数调用：

```text
$ sudo strace -e trace=write docker ps

```

#### 8.1.2 第二规则：迭代缩小范围定位法则

容器系统的错误，一般是由多个层面的问题叠加出现的。当故障发生的时候，通过工具收集的信息很多，你很难一下做出准确的判断。为了准确有效的排除故障，可能一张准确的事故原因脑图可以更方便的记录你的判断路径。在已知信息的参考下，对于可能的情况做出推演判断，然后在进行有效的故障恢复的系统操作。

#### 8.1.3 第三规则：事后故障总结法则

作为运维故障的案例，实际发生的问题多发生在一个多环境交叉的兼容环境之下。从科学的角度来讲，我们有很多不可预知的情况需要考虑优化配置。但是，因为每个运维团队的知识体系并不能保证是最新的，所以，我们需要对每一次事故做一次最严格的事故维护总结，并归档成事故排错手册。每一位新运维人员要求对故障排错手册里面的事故能进行模拟实战推演，帮助运维能快速掌握容器运维的场景和解决思路。

### 8.2 Kubernetes容器线上故障排错法则

Kubernetes容器集群系统是一套管理容器应用的分布式系统，包含kube-apiserver，kube-controller，kube-scheduler, kubelet, kube-proxy等众多核心组件，并且为了Pod之间的网络通信和服务发现、容器存储等特性，还需要安装CNI网络插件、CSI存储插件、CoreDNS等相关依赖，可以这么说，因为组件的增加，势必会让问题更加难以确认和排错。

### 8.3 Docker应用镜像运行故障排错案例分析

### 8.4 Kubernetes集群Service层网故障排错案例分析

